{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7377e6-06d6-46d0-b2be-d13cba0a6c33",
   "metadata": {},
   "source": [
    "Pour utiliser wikidata\n",
    "\n",
    "SELECT ?montagne ?pic ?label ?taille ?range ?rangelabel WHERE {\n",
    "  ?montagne wdt:P31 wd:Q8502;\n",
    "    wdt:P17 wd:Q142;\n",
    "    wdt:P18 ?pic;\n",
    "    rdfs:label ?label;\n",
    "    wdt:P2044 ?taille;\n",
    "    wdt:P4552 ?range.\n",
    "    ?range rdfs:label ?rangelabel \n",
    "  FILTER(lang(?label)=\"fr\" && lang(?rangelabel)=\"fr\").\n",
    "}\n",
    "LIMIT 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdbd9c5-fd8b-405f-9a8b-982da704c40d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'login': 'TheotimCDV', 'id': 181193070, 'node_id': 'U_kgDOCszJbg', 'avatar_url': 'https://avatars.githubusercontent.com/u/181193070?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/TheotimCDV', 'html_url': 'https://github.com/TheotimCDV', 'followers_url': 'https://api.github.com/users/TheotimCDV/followers', 'following_url': 'https://api.github.com/users/TheotimCDV/following{/other_user}', 'gists_url': 'https://api.github.com/users/TheotimCDV/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/TheotimCDV/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/TheotimCDV/subscriptions', 'organizations_url': 'https://api.github.com/users/TheotimCDV/orgs', 'repos_url': 'https://api.github.com/users/TheotimCDV/repos', 'events_url': 'https://api.github.com/users/TheotimCDV/events{/privacy}', 'received_events_url': 'https://api.github.com/users/TheotimCDV/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False, 'name': None, 'company': None, 'blog': '', 'location': None, 'email': None, 'hireable': None, 'bio': None, 'twitter_username': None, 'public_repos': 3, 'public_gists': 0, 'followers': 0, 'following': 0, 'created_at': '2024-09-11T06:24:24Z', 'updated_at': '2025-02-04T08:27:50Z'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://api.github.com/users/TheotimCDV\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99902cc1-b329-4dc1-a5b3-7014e4612f39",
   "metadata": {},
   "source": [
    "SELECT DISTINCT ?film ?label (GROUP_CONCAT(DISTINCT ?originname; separator=\", \") AS ?origins) WHERE {\n",
    "  ?film wdt:P31 wd:Q11424;  # Instance de film\n",
    "        wdt:P166 wd:Q102427;  # A gagn√© un Oscar\n",
    "        wdt:P495 ?origin;  # Pays d'origine\n",
    "        rdfs:label ?label.\n",
    "  \n",
    "  ?origin rdfs:label ?originname.\n",
    "\n",
    "  FILTER(lang(?label)=\"en\" && lang(?originname)=\"en\")\n",
    "}\n",
    "GROUP BY ?film ?label\n",
    "LIMIT 100\n",
    "\n",
    "#liste des films ayant gagne l'oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9795a6-1562-49dc-8b08-c0e5667389c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\squin\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\squin\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\squin\\anaconda3\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c9c3bb-6f22-4020-abb8-91bcc2c25b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encyclop√©die libre que vous pouvez am√©liorer\n",
      "Le ch√¢teau de Montsoreau est un ch√¢teau fran√ßais de style gothique et Renaissance situ√© dans le Val de Loire sur la commune de Montsoreau dans le sud-est du d√©partement de Maine-et-Loire en r√©gion Pays de la Loire.\n",
      "Il abrite depuis le 8 avril 2016 le ch√¢teau de Montsoreau - mus√©e d'Art contemporain. B√¢ti √† un emplacement strat√©gique, sur un promontoire rocheux √† la confluence de la Loire et de la Vienne, il se trouve √† l'intersection de trois r√©gions¬†: l'Anjou, le Poitou et la Touraine. √âdifice de transition entre le ch√¢teau fort  et le palais urbain, il a pour particularit√© d'√™tre le seul ch√¢teau de la Loire construit √† m√™me le lit du fleuve.\n",
      "Le ch√¢teau de Montsoreau a √©t√© immortalis√© √† de nombreuses reprises, notamment par Alexandre Dumas dans son roman La Dame de Monsoreau √©crit entre 1845 et 1846, par J. M. W. Turner dans une aquarelle repr√©sentant le ch√¢teau et le bec de Vienne, par Fran√ßois Rabelais dans Gargantua, qui donne Montsoreau en r√©compense √† Ithybole apr√®s sa victoire, et par Auguste Rodin, qui l'id√©alise dans un dessin conserv√© au mus√©e Rodin.\n",
      "Class√© monument historique en 1862, il est inscrit au patrimoine mondial de l'humanit√© par l'UNESCO au titre de l'inscription de l'ensemble du Val de Loire entre Sully-sur-Loire et Chalonnes-sur-Loire.\n",
      "Wikip√©dia est un projet d‚Äôencyclop√©die collective en ligne, universelle, multilingue et fonctionnant sur le principe du wiki. Ce projet vise √† offrir un contenu librement r√©utilisable, objectif et v√©rifiable, que chacun peut modifier et am√©liorer.\n",
      "Wikip√©dia est d√©finie par des principes fondateurs. Son contenu est sous licence Creative Commons BY-SA. Il peut √™tre copi√© et r√©utilis√© sous la m√™me licence, sous r√©serve d'en respecter les conditions. Wikip√©dia fournit tous ses contenus gratuitement, sans publicit√©, et sans recourir √† l'exploitation des donn√©es personnelles de ses utilisateurs.\n",
      "Les r√©dacteurs des articles de Wikip√©dia sont b√©n√©voles. Ils coordonnent leurs efforts au sein d'une communaut√© collaborative, sans dirigeant.\n",
      "Chacun peut publier imm√©diatement du contenu en ligne, √† condition de respecter les r√®gles essentielles √©tablies par la Fondation Wikimedia et par la communaut√©¬†; par exemple, la v√©rifiabilit√© du contenu, l'admissibilit√© des articles et garder une attitude cordiale.\n",
      "De nombreuses pages d‚Äôaide sont √† votre disposition, notamment pour cr√©er un article, modifier un article ou ins√©rer une image. N‚Äôh√©sitez pas √† poser une question pour √™tre aid√© dans vos premiers pas, notamment dans un des  projets th√©matiques ou dans divers espaces de discussion.\n",
      "Les pages de discussion servent √† centraliser les r√©flexions et les remarques permettant d‚Äôam√©liorer les articles.\n",
      "Images de qualit√© sur Wikim√©dia Commons\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la page √† parser\n",
    "url = \"https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal\"\n",
    "\n",
    "# R√©cup√©ration du contenu HTML de la page\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")  # Utilisation de lxml pour un parsing rapide\n",
    "\n",
    "    # Extraction de tous les titres d'articles (exemple avec <h2>)\n",
    "    titles = soup.find_all(\"p\")\n",
    "    for title in titles:\n",
    "        titre = title.text.strip()\n",
    "        print(title.text.strip())  # Affichage du texte des titres\n",
    "        \n",
    "        \n",
    "else:\n",
    "    print(f\"Erreur lors de l'acc√®s √† la page (code {response.status_code})\")\n",
    "    \n",
    "print(titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f55b38-3a82-4282-8ae7-5dddeef86d81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nltk.stem.porter (from versions: none)\n",
      "ERROR: No matching distribution found for nltk.stem.porter\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PorterStemmer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install nltk.stem.porter import PorterStemmer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m porter \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m titre:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(porter\u001b[38;5;241m.\u001b[39mstem(word), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PorterStemmer' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "for words in titre:\n",
    "    print(porter.stem(word), end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04980f07-84ca-4729-886d-8ae3fe36a28d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\squin\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\squin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48fdd0fe-e3e9-4ede-9bec-f50accc030a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"running\"))  # Exemple de stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c941b44-69ff-4e1a-9dab-23cf24b0f2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-grams :\n",
      "de: 26\n",
      "et: 16\n",
      "le: 12\n",
      "√†: 12\n",
      "la: 11\n",
      "un: 9\n",
      "dans: 9\n",
      "par: 9\n",
      "ch√¢teau: 7\n",
      "du: 6\n",
      "\n",
      "2-grams :\n",
      "ch√¢teau de: 4\n",
      "de Montsoreau: 4\n",
      "de la: 4\n",
      "le ch√¢teau: 3\n",
      "Le ch√¢teau: 2\n",
      "est un: 2\n",
      "dans le: 2\n",
      "Val de: 2\n",
      "de Loire: 2\n",
      "la Loire: 2\n",
      "\n",
      "3-grams :\n",
      "ch√¢teau de Montsoreau: 3\n",
      "Le ch√¢teau de: 2\n",
      "Val de Loire: 2\n",
      "de la Loire: 2\n",
      "L'encyclop√©die libre que: 1\n",
      "libre que vous: 1\n",
      "que vous pouvez: 1\n",
      "vous pouvez am√©liorer: 1\n",
      "pouvez am√©liorer Le: 1\n",
      "am√©liorer Le ch√¢teau: 1\n",
      "\n",
      "4-grams :\n",
      "Le ch√¢teau de Montsoreau: 2\n",
      "L'encyclop√©die libre que vous: 1\n",
      "libre que vous pouvez: 1\n",
      "que vous pouvez am√©liorer: 1\n",
      "vous pouvez am√©liorer Le: 1\n",
      "pouvez am√©liorer Le ch√¢teau: 1\n",
      "am√©liorer Le ch√¢teau de: 1\n",
      "ch√¢teau de Montsoreau est: 1\n",
      "de Montsoreau est un: 1\n",
      "Montsoreau est un ch√¢teau: 1\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "sentence = texte_complet\n",
    "for n in range(1, 5):  # De 1-gram √† 4-gram\n",
    "    print(f\"\\n{n}-grams :\")\n",
    "    n_grams = list(ngrams(texte_complet.split(), n))  # Cr√©ation des n-grams sous forme de liste\n",
    "    n_gram_counts = Counter(n_grams)  # Compter les occurrences\n",
    "    ngram_test = {}\n",
    "    \n",
    "    top_10_ngrams = n_gram_counts.most_common(10)\n",
    "    for ngram, count in top_10_ngrams:\n",
    "        print(f\"{' '.join(ngram)}: {count}\")\n",
    "\n",
    "    # Affichage des n-grams et de leurs occurrences\n",
    "    #for ngram, count in n_gram_counts.items():\n",
    "\n",
    "      #  print(f\"{ngram}: {count}\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc39cc41-ea45-4a75-bb58-33412d038698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encyclop√©die libre que vous pouvez am√©liorer\n",
      "\n",
      "Le ch√¢teau de Montsoreau est un ch√¢teau fran√ßais de style gothique et Renaissance situ√© dans le Val de Loire sur la commune de Montsoreau dans le sud-est du d√©partement de Maine-et-Loire en r√©gion Pays de la Loire.\n",
      "\n",
      "Il abrite depuis le 8 avril 2016 le ch√¢teau de Montsoreau - mus√©e d'Art contemporain. B√¢ti √† un emplacement strat√©gique, sur un promontoire rocheux √† la confluence de la Loire et de la Vienne, il se trouve √† l'intersection de trois r√©gions¬†: l'Anjou, le Poitou et la Touraine. √âdifice de transition entre le ch√¢teau fort  et le palais urbain, il a pour particularit√© d'√™tre le seul ch√¢teau de la Loire construit √† m√™me le lit du fleuve.\n",
      "\n",
      "Le ch√¢teau de Montsoreau a √©t√© immortalis√© √† de nombreuses reprises, notamment par Alexandre Dumas dans son roman La Dame de Monsoreau √©crit entre 1845 et 1846, par J. M. W. Turner dans une aquarelle repr√©sentant le ch√¢teau et le bec de Vienne, par Fran√ßois Rabelais dans Gargantua, qui donne Montsoreau en r√©compense √† Ithybole apr√®s sa victoire, et par Auguste Rodin, qui l'id√©alise dans un dessin conserv√© au mus√©e Rodin.\n",
      "\n",
      "Class√© monument historique en 1862, il est inscrit au patrimoine mondial de l'humanit√© par l'UNESCO au titre de l'inscription de l'ensemble du Val de Loire entre Sully-sur-Loire et Chalonnes-sur-Loire.\n",
      "\n",
      "Wikip√©dia est un projet d‚Äôencyclop√©die collective en ligne, universelle, multilingue et fonctionnant sur le principe du wiki. Ce projet vise √† offrir un contenu librement r√©utilisable, objectif et v√©rifiable, que chacun peut modifier et am√©liorer.\n",
      "\n",
      "Wikip√©dia est d√©finie par des principes fondateurs. Son contenu est sous licence Creative Commons BY-SA. Il peut √™tre copi√© et r√©utilis√© sous la m√™me licence, sous r√©serve d'en respecter les conditions. Wikip√©dia fournit tous ses contenus gratuitement, sans publicit√©, et sans recourir √† l'exploitation des donn√©es personnelles de ses utilisateurs.\n",
      "\n",
      "Les r√©dacteurs des articles de Wikip√©dia sont b√©n√©voles. Ils coordonnent leurs efforts au sein d'une communaut√© collaborative, sans dirigeant.\n",
      "\n",
      "Chacun peut publier imm√©diatement du contenu en ligne, √† condition de respecter les r√®gles essentielles √©tablies par la Fondation Wikimedia et par la communaut√©¬†; par exemple, la v√©rifiabilit√© du contenu, l'admissibilit√© des articles et garder une attitude cordiale.\n",
      "\n",
      "De nombreuses pages d‚Äôaide sont √† votre disposition, notamment pour cr√©er un article, modifier un article ou ins√©rer une image. N‚Äôh√©sitez pas √† poser une question pour √™tre aid√© dans vos premiers pas, notamment dans un des  projets th√©matiques ou dans divers espaces de discussion.\n",
      "\n",
      "Les pages de discussion servent √† centraliser les r√©flexions et les remarques permettant d‚Äôam√©liorer les articles.\n",
      "\n",
      "Images de qualit√© sur Wikim√©dia Commons\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la page √† parser\n",
    "url = \"https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal\"\n",
    "\n",
    "# R√©cup√©ration du contenu HTML de la page\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")  # Utilisation de lxml pour un parsing rapide\n",
    "\n",
    "    # Extraction de tous les paragraphes (<p>)\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "    # Stocker les paragraphes dans une seule variable texte\n",
    "    texte_complet = \"\\n\\n\".join(p.text.strip() for p in paragraphs if p.text.strip())\n",
    "\n",
    "    # Affichage du texte complet\n",
    "    print(texte_complet)\n",
    "\n",
    "    # (Optionnel) Enregistrement dans un fichier texte\n",
    "    with open(\"wikipedia_paragraphs.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(texte_complet)\n",
    "\n",
    "else:\n",
    "    print(f\"Erreur lors de l'acc√®s √† la page (code {response.status_code})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456ce3fa-8424-40db-8f69-e365d6631e84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2570653632.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[44], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    from nltk\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentence =\"He goes to school daily\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "primt(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bc28f0e-fdca-4e7d-acff-8f69eea533b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ac18ff9-c74f-4722-8b9f-a891d1692a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/ca/45/7b43e89b30fe73e32fd8b8ab80c407d326761530a88abd823ec8623772a6/spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/de/30/ceb9217cdba72bc0bf8466e373e12e5a42945cc85eda0a7c479e319e07ae/murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/56/c8/75f75889401b20f4c3a7c5965dda09df42913e904ddc2ffe7ef3bdf25061/cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.4.0,>=8.3.4 from https://files.pythonhosted.org/packages/d9/98/f910b8d8113ab9b955a68e9bbf0d5bd0e828f22dd6d3c226af6ec3970817/thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/bb/da/657a685f63028dcb00ccdc4ac125ed347c8bff6fa0dab6a9eb3dc45f3223/srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/d0/cc/0a838ba5ca64dc832aa43f727bd586309846b0ffb2ce52422543e6075e8a/typer-0.15.1-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/c3/6b/068c2ea7a712bf805c62445bd9e9c06d7340358ef2824150eceac027444b/langcodes-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/5d/e9/5a5ffd9b286db82be70d677d0a91e4d58f7912bb8dd026ddeeb4abe70679/language_data-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for blis<1.3.0,>=1.2.0 from https://files.pythonhosted.org/packages/c4/d9/b647ef53c33c82c1fa2ed217c5793de551a38fb1e5b2430f59c3ecba4c86/blis-1.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-1.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\squin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/1f/6e/b64600156934dab14cc8b403095a9ea8bd722aad2e775673c68346b76220/cloudpathlib-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for marisa-trie>=1.1.0 from https://files.pythonhosted.org/packages/fc/98/574b4e143e0a2f5f71af8716b6c4a8a46220f75a6e0847ce7d11ee0ba4aa/marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.2 MB 4.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/12.2 MB 9.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/12.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/12.2 MB 12.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.0/12.2 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.5/12.2 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.2/12.2 MB 13.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.2/12.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.4/12.2 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.4/12.2 MB 16.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.5/12.2 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.2 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.9/12.2 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.8/12.2 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/183.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 183.0/183.0 kB ? eta 0:00:00\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.6/632.6 kB 38.9 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.2/1.5 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 31.5 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.3/50.3 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading blis-1.2.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.3/6.2 MB 40.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.2/6.2 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.1/6.2 MB 32.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.1/6.2 MB 29.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.1/6.2 MB 27.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 24.9 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.4 MB 32.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.6/5.4 MB 33.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.3/5.4 MB 34.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 31.3 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 242.4/242.4 kB ? eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 152.0/152.0 kB ? eta 0:00:00\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, rich, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 rich-13.9.4 shellingham-1.5.4 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "579222a5-1c72-4506-8e76-f60281f0b3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m[x] No compatible package found for 'fr_core_web_sm' (spaCy v3.8.4)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_web_sm\n",
    "\n",
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0073070a-7323-4c66-b84c-d1170ac7ae09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He PRON nsubj\n",
      "goes VERB ROOT\n",
      "to ADP prep\n",
      "school NOUN pobj\n",
      "daily ADV advmod\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"He goes to school daily\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e54ea-cfe4-4b94-8d79-850c75178a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cad1016-b13f-4aa9-8dc0-2dd55e402b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenue dans le jeu 'Devine le nombre' !\n",
      "J'ai choisi un nombre entre 1 et 100. √Ä toi de le deviner !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop haut ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bravo ! Tu as trouv√© le nombre 93 en 7 essais. üéâ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def jeu_devine_nombre():\n",
    "    print(\"Bienvenue dans le jeu 'Devine le nombre' !\")\n",
    "    print(\"J'ai choisi un nombre entre 1 et 100. √Ä toi de le deviner !\")\n",
    "\n",
    "    nombre_secret = random.randint(1, 100)\n",
    "    tentative = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choix = int(input(\"Entre un nombre : \"))\n",
    "            tentative += 1\n",
    "            \n",
    "            if choix < nombre_secret:\n",
    "                print(\"Trop bas ! Essaie encore.\")\n",
    "            elif choix > nombre_secret:\n",
    "                print(\"Trop haut ! Essaie encore.\")\n",
    "            else:\n",
    "                print(f\"Bravo ! Tu as trouv√© le nombre {nombre_secret} en {tentative} essais. üéâ\")\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"Oups ! Entre un nombre valide.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jeu_devine_nombre()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f2da81-8c4f-469f-81fd-8f198ed07e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \n\u001b[0;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mlaod(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m text_to_analyze \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\cli\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Needed for testing\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download \u001b[38;5;28;01mas\u001b[39;00m download_module  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app, setup_cli  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\cli\\download.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urljoin\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyper\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m about\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\typer\\__init__.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_file \u001b[38;5;28;01mas\u001b[39;00m open_file\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors \u001b[38;5;28;01mas\u001b[39;00m colors\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Typer \u001b[38;5;28;01mas\u001b[39;00m Typer\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m launch \u001b[38;5;28;01mas\u001b[39;00m launch\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run \u001b[38;5;28;01mas\u001b[39;00m run\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\typer\\main.py:57\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Traceback\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rich_utils\n\u001b[1;32m---> 57\u001b[0m     console_stderr \u001b[38;5;241m=\u001b[39m rich_utils\u001b[38;5;241m.\u001b[39m_get_rich_console(stderr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     rich \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\typer\\rich_utils.py:129\u001b[0m, in \u001b[0;36m_get_rich_console\u001b[1;34m(stderr)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_rich_console\u001b[39m(stderr: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Console:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Console(\n\u001b[0;32m    130\u001b[0m         theme\u001b[38;5;241m=\u001b[39mTheme(\n\u001b[0;32m    131\u001b[0m             {\n\u001b[0;32m    132\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_OPTION,\n\u001b[0;32m    133\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_SWITCH,\n\u001b[0;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_option\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_NEGATIVE_OPTION,\n\u001b[0;32m    135\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_switch\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_NEGATIVE_SWITCH,\n\u001b[0;32m    136\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetavar\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_METAVAR,\n\u001b[0;32m    137\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetavar_sep\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_METAVAR_SEPARATOR,\n\u001b[0;32m    138\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_USAGE,\n\u001b[0;32m    139\u001b[0m             },\n\u001b[0;32m    140\u001b[0m         ),\n\u001b[0;32m    141\u001b[0m         highlighter\u001b[38;5;241m=\u001b[39mhighlighter,\n\u001b[0;32m    142\u001b[0m         color_system\u001b[38;5;241m=\u001b[39mCOLOR_SYSTEM,\n\u001b[0;32m    143\u001b[0m         force_terminal\u001b[38;5;241m=\u001b[39mFORCE_TERMINAL,\n\u001b[0;32m    144\u001b[0m         width\u001b[38;5;241m=\u001b[39mMAX_WIDTH,\n\u001b[0;32m    145\u001b[0m         stderr\u001b[38;5;241m=\u001b[39mstderr,\n\u001b[0;32m    146\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\console.py:691\u001b[0m, in \u001b[0;36mConsole.__init__\u001b[1;34m(self, color_system, force_terminal, force_jupyter, force_interactive, soft_wrap, theme, stderr, file, quiet, width, height, style, no_color, tab_size, record, markup, emoji, emoji_variant, highlight, log_time, log_path, log_time_format, highlighter, legacy_windows, safe_box, get_datetime, get_time, _environ)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_emoji_variant: Optional[EmojiVariant] \u001b[38;5;241m=\u001b[39m emoji_variant\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_highlight \u001b[38;5;241m=\u001b[39m highlight\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegacy_windows: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 691\u001b[0m     (detect_legacy_windows() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_jupyter)\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m legacy_windows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m legacy_windows\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    697\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_environ\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOLUMNS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\console.py:590\u001b[0m, in \u001b[0;36mdetect_legacy_windows\u001b[1;34m()\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_legacy_windows\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    589\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Detect legacy Windows.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WINDOWS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_windows_console_features()\u001b[38;5;241m.\u001b[39mvt\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\console.py:584\u001b[0m, in \u001b[0;36mget_windows_console_features\u001b[1;34m()\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _windows_console_features\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_windows\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_windows_console_features\n\u001b[1;32m--> 584\u001b[0m _windows_console_features \u001b[38;5;241m=\u001b[39m get_windows_console_features()\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _windows_console_features\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\_windows.py:48\u001b[0m, in \u001b[0;36mget_windows_console_features\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m handle \u001b[38;5;241m=\u001b[39m GetStdHandle()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     console_mode \u001b[38;5;241m=\u001b[39m GetConsoleMode(handle)\n\u001b[0;32m     49\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LegacyWindowsError:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\_win32_console.py:111\u001b[0m, in \u001b[0;36mGetConsoleMode\u001b[1;34m(std_handle)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the current input mode of a console's input buffer\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03mor the current output mode of a console screen buffer.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m        https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m console_mode \u001b[38;5;241m=\u001b[39m wintypes\u001b[38;5;241m.\u001b[39mDWORD()\n\u001b[1;32m--> 111\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(_GetConsoleMode(std_handle, console_mode))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LegacyWindowsError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get legacy Windows Console Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.laod(\"en_core_web_sm\")\n",
    "\n",
    "text_to_analyze = \"cat\"\n",
    "doc = nlp(text_to_analyze)\n",
    "\n",
    "vector_list = [token.vector for token in doc]\n",
    "print(\"Vecteurs de '{}' : {}\".format(text_to_analyze, vector_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855734e-92f3-4054-9155-4588b824347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vecteur du mot 'this':\", cbow_model.vw[\"this\"])\n",
    "\n",
    "print(\"Similarite entre 'this' et 'class':\", cbow_model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de869ce-0a0b-499e-b52a-beedeeec1a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'fr_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Charger le mod√®le spaCy\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Texte √† analyser\u001b[39;00m\n\u001b[0;32m      5\u001b[0m text_to_analyze \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis is the capital of France.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn 2015, its population was# Analyser le texte\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'fr_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "# Charger le mod√®le spaCy\n",
    "nlp = spacy.load(\"fr_core_web_sm\")\n",
    "# Texte √† analyser\n",
    "text_to_analyze = \"Paris is the capital of France.\" + \"In 2015, its population was# Analyser le texte\"\n",
    "doc = nlp(texte_complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76757369-e06c-4525-871e-3ced86d4414a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entit√©: un, D√©but: 77, Fin: 79, Cat√©gorie: ORG\n",
      "Entit√©: Renaissance, D√©but: 118, Fin: 129, Cat√©gorie: ORG\n",
      "Entit√©: Val de Loire, D√©but: 144, Fin: 156, Cat√©gorie: ORG\n",
      "Entit√©: dans, D√©but: 186, Fin: 190, Cat√©gorie: NORP\n",
      "Entit√©: Maine, D√©but: 220, Fin: 225, Cat√©gorie: GPE\n",
      "Entit√©: Il abrite depuis le, D√©but: 264, Fin: 283, Cat√©gorie: PERSON\n",
      "Entit√©: 8 avril 2016, D√©but: 284, Fin: 296, Cat√©gorie: TIME\n",
      "Entit√©: ch√¢teau de Montsoreau - mus√©e, D√©but: 300, Fin: 329, Cat√©gorie: ORG\n",
      "Entit√©: un, D√©but: 357, Fin: 359, Cat√©gorie: ORG\n",
      "Entit√©: sur un promontoire rocheux √† la confluence de la Loire et de la Vienne, D√©but: 385, Fin: 455, Cat√©gorie: ORG\n",
      "Entit√©: il se trouve, D√©but: 457, Fin: 469, Cat√©gorie: PERSON\n",
      "Entit√©: Poitou, D√©but: 518, Fin: 524, Cat√©gorie: GPE\n",
      "Entit√©: Touraine, D√©but: 531, Fin: 539, Cat√©gorie: ORG\n",
      "Entit√©: ch√¢teau fort  et, D√©but: 572, Fin: 588, Cat√©gorie: FAC\n",
      "Entit√©: ch√¢teau de la Loire, D√©but: 646, Fin: 665, Cat√©gorie: ORG\n",
      "Entit√©: m√™me le, D√©but: 678, Fin: 685, Cat√©gorie: PERSON\n",
      "Entit√©: Le ch√¢teau de Montsoreau, D√©but: 702, Fin: 726, Cat√©gorie: ORG\n",
      "Entit√©: Alexandre Dumas, D√©but: 785, Fin: 800, Cat√©gorie: PERSON\n",
      "Entit√©: dans, D√©but: 801, Fin: 805, Cat√©gorie: NORP\n",
      "Entit√©: La Dame de Monsoreau, D√©but: 816, Fin: 836, Cat√©gorie: ORG\n",
      "Entit√©: 1845, D√©but: 849, Fin: 853, Cat√©gorie: DATE\n",
      "Entit√©: 1846, D√©but: 857, Fin: 861, Cat√©gorie: DATE\n",
      "Entit√©: J. M. W. Turner, D√©but: 867, Fin: 882, Cat√©gorie: PERSON\n",
      "Entit√©: dans, D√©but: 883, Fin: 887, Cat√©gorie: NORP\n",
      "Entit√©: une, D√©but: 888, Fin: 891, Cat√©gorie: ORG\n",
      "Entit√©: ch√¢teau et le bec de Vienne, D√©but: 918, Fin: 945, Cat√©gorie: ORG\n",
      "Entit√©: Fran√ßois Rabelais, D√©but: 951, Fin: 968, Cat√©gorie: ORG\n",
      "Entit√©: Gargantua, D√©but: 974, Fin: 983, Cat√©gorie: PERSON\n",
      "Entit√©: Ithybole, D√©but: 1022, Fin: 1030, Cat√©gorie: ORG\n",
      "Entit√©: Auguste Rodin, D√©but: 1057, Fin: 1070, Cat√©gorie: PERSON\n",
      "Entit√©: qui l'id√©alise, D√©but: 1072, Fin: 1086, Cat√©gorie: ORG\n",
      "Entit√©: un, D√©but: 1092, Fin: 1094, Cat√©gorie: ORG\n",
      "Entit√©: Class√©, D√©but: 1128, Fin: 1134, Cat√©gorie: ORG\n",
      "Entit√©: 1862, D√©but: 1158, Fin: 1162, Cat√©gorie: DATE\n",
      "Entit√©: titre de l'inscription de l'ensemble, D√©but: 1231, Fin: 1267, Cat√©gorie: PERSON\n",
      "Entit√©: Val de Loire, D√©but: 1271, Fin: 1283, Cat√©gorie: ORG\n",
      "Entit√©: Wikip√©dia, D√©but: 1331, Fin: 1340, Cat√©gorie: GPE\n",
      "Entit√©: un, D√©but: 1345, Fin: 1347, Cat√©gorie: ORG\n",
      "Entit√©: d‚Äôencyclop√©die, D√©but: 1355, Fin: 1369, Cat√©gorie: PERSON\n",
      "Entit√©: universelle, D√©but: 1391, Fin: 1402, Cat√©gorie: ORG\n",
      "Entit√©: multilingue, D√©but: 1404, Fin: 1415, Cat√©gorie: PERSON\n",
      "Entit√©: un, D√©but: 1481, Fin: 1483, Cat√©gorie: ORG\n",
      "Entit√©: Wikip√©dia, D√©but: 1580, Fin: 1589, Cat√©gorie: GPE\n",
      "Entit√©: d√©finie, D√©but: 1594, Fin: 1601, Cat√©gorie: PERSON\n",
      "Entit√©: Creative Commons BY-SA, D√©but: 1661, Fin: 1683, Cat√©gorie: ORG\n",
      "Entit√©: Il peut √™tre copi√©, D√©but: 1685, Fin: 1703, Cat√©gorie: PERSON\n",
      "Entit√©: la m√™me licence, D√©but: 1722, Fin: 1737, Cat√©gorie: FAC\n",
      "Entit√©: Wikip√©dia, D√©but: 1783, Fin: 1792, Cat√©gorie: GPE\n",
      "Entit√©: Wikip√©dia, D√©but: 1961, Fin: 1970, Cat√©gorie: GPE\n",
      "Entit√©: Chacun, D√©but: 2074, Fin: 2080, Cat√©gorie: ORG\n",
      "Entit√©: par exemple, D√©but: 2237, Fin: 2248, Cat√©gorie: PERSON\n",
      "Entit√©: un, D√©but: 2416, Fin: 2418, Cat√©gorie: ORG\n",
      "Entit√©: un, D√©but: 2437, Fin: 2439, Cat√©gorie: ORG\n",
      "Entit√©: √™tre aid√© dans, D√©but: 2510, Fin: 2524, Cat√©gorie: PERSON\n",
      "Entit√©: dans, D√©but: 2553, Fin: 2557, Cat√©gorie: NORP\n",
      "Entit√©: un, D√©but: 2558, Fin: 2560, Cat√©gorie: ORG\n",
      "Entit√©: dans, D√©but: 2589, Fin: 2593, Cat√©gorie: NORP\n",
      "Entit√©: Wikim√©dia Commons, D√©but: 2763, Fin: 2780, Cat√©gorie: ORG\n"
     ]
    }
   ],
   "source": [
    "# Afficher les informations sur les entit√©s\n",
    "for entity in doc.ents:\n",
    "    entity_text = entity.text\n",
    "    start_char = entity.start_char\n",
    "    end_char = entity.end_char\n",
    "    label = entity.label_\n",
    "    print(\"Entit√©: {}, D√©but: {}, Fin: {}, Cat√©gorie: {}\".format(entity_text,\n",
    "    start_char, end_char, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b90465f0-af41-4b8d-a5ad-01afa9256819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading vader_location: Package 'vader_location' not\n",
      "[nltk_data]     found in index\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\squin/nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvader_location\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[1;32m----> 5\u001b[0m sia \u001b[38;5;241m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[0;32m      6\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m sia\u001b[38;5;241m.\u001b[39mpolarity_scores(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis movie is good\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentiment)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\sentiment\\vader.py:340\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.__init__\u001b[1;34m(self, lexicon_file)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    338\u001b[0m     lexicon_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    339\u001b[0m ):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon_file \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mload(lexicon_file)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_lex_dict()\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstants \u001b[38;5;241m=\u001b[39m VaderConstants()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\squin/nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_location')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment = sia.polarity_scores(\"this movie is good\")\n",
    "print(sentiment)\n",
    "sentiment = sia.polarity_scores(\"this movie is not very good\")\n",
    "print(sentiment)\n",
    "sentiment = sia.polarity_scores(\"this movie is bad\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcd26c-de59-415f-b224-70a40bd0fc88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
