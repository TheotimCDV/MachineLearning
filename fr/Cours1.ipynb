{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7377e6-06d6-46d0-b2be-d13cba0a6c33",
   "metadata": {},
   "source": [
    "Pour utiliser wikidata\n",
    "\n",
    "SELECT ?montagne ?pic ?label ?taille ?range ?rangelabel WHERE {\n",
    "  ?montagne wdt:P31 wd:Q8502;\n",
    "    wdt:P17 wd:Q142;\n",
    "    wdt:P18 ?pic;\n",
    "    rdfs:label ?label;\n",
    "    wdt:P2044 ?taille;\n",
    "    wdt:P4552 ?range.\n",
    "    ?range rdfs:label ?rangelabel \n",
    "  FILTER(lang(?label)=\"fr\" && lang(?rangelabel)=\"fr\").\n",
    "}\n",
    "LIMIT 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdbd9c5-fd8b-405f-9a8b-982da704c40d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'login': 'TheotimCDV', 'id': 181193070, 'node_id': 'U_kgDOCszJbg', 'avatar_url': 'https://avatars.githubusercontent.com/u/181193070?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/TheotimCDV', 'html_url': 'https://github.com/TheotimCDV', 'followers_url': 'https://api.github.com/users/TheotimCDV/followers', 'following_url': 'https://api.github.com/users/TheotimCDV/following{/other_user}', 'gists_url': 'https://api.github.com/users/TheotimCDV/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/TheotimCDV/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/TheotimCDV/subscriptions', 'organizations_url': 'https://api.github.com/users/TheotimCDV/orgs', 'repos_url': 'https://api.github.com/users/TheotimCDV/repos', 'events_url': 'https://api.github.com/users/TheotimCDV/events{/privacy}', 'received_events_url': 'https://api.github.com/users/TheotimCDV/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False, 'name': None, 'company': None, 'blog': '', 'location': None, 'email': None, 'hireable': None, 'bio': None, 'twitter_username': None, 'public_repos': 3, 'public_gists': 0, 'followers': 0, 'following': 0, 'created_at': '2024-09-11T06:24:24Z', 'updated_at': '2025-02-04T08:27:50Z'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://api.github.com/users/TheotimCDV\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99902cc1-b329-4dc1-a5b3-7014e4612f39",
   "metadata": {},
   "source": [
    "SELECT DISTINCT ?film ?label (GROUP_CONCAT(DISTINCT ?originname; separator=\", \") AS ?origins) WHERE {\n",
    "  ?film wdt:P31 wd:Q11424;  # Instance de film\n",
    "        wdt:P166 wd:Q102427;  # A gagné un Oscar\n",
    "        wdt:P495 ?origin;  # Pays d'origine\n",
    "        rdfs:label ?label.\n",
    "  \n",
    "  ?origin rdfs:label ?originname.\n",
    "\n",
    "  FILTER(lang(?label)=\"en\" && lang(?originname)=\"en\")\n",
    "}\n",
    "GROUP BY ?film ?label\n",
    "LIMIT 100\n",
    "\n",
    "#liste des films ayant gagne l'oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9795a6-1562-49dc-8b08-c0e5667389c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\squin\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\squin\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\squin\\anaconda3\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c9c3bb-6f22-4020-abb8-91bcc2c25b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encyclopédie libre que vous pouvez améliorer\n",
      "Le château de Montsoreau est un château français de style gothique et Renaissance situé dans le Val de Loire sur la commune de Montsoreau dans le sud-est du département de Maine-et-Loire en région Pays de la Loire.\n",
      "Il abrite depuis le 8 avril 2016 le château de Montsoreau - musée d'Art contemporain. Bâti à un emplacement stratégique, sur un promontoire rocheux à la confluence de la Loire et de la Vienne, il se trouve à l'intersection de trois régions : l'Anjou, le Poitou et la Touraine. Édifice de transition entre le château fort  et le palais urbain, il a pour particularité d'être le seul château de la Loire construit à même le lit du fleuve.\n",
      "Le château de Montsoreau a été immortalisé à de nombreuses reprises, notamment par Alexandre Dumas dans son roman La Dame de Monsoreau écrit entre 1845 et 1846, par J. M. W. Turner dans une aquarelle représentant le château et le bec de Vienne, par François Rabelais dans Gargantua, qui donne Montsoreau en récompense à Ithybole après sa victoire, et par Auguste Rodin, qui l'idéalise dans un dessin conservé au musée Rodin.\n",
      "Classé monument historique en 1862, il est inscrit au patrimoine mondial de l'humanité par l'UNESCO au titre de l'inscription de l'ensemble du Val de Loire entre Sully-sur-Loire et Chalonnes-sur-Loire.\n",
      "Wikipédia est un projet d’encyclopédie collective en ligne, universelle, multilingue et fonctionnant sur le principe du wiki. Ce projet vise à offrir un contenu librement réutilisable, objectif et vérifiable, que chacun peut modifier et améliorer.\n",
      "Wikipédia est définie par des principes fondateurs. Son contenu est sous licence Creative Commons BY-SA. Il peut être copié et réutilisé sous la même licence, sous réserve d'en respecter les conditions. Wikipédia fournit tous ses contenus gratuitement, sans publicité, et sans recourir à l'exploitation des données personnelles de ses utilisateurs.\n",
      "Les rédacteurs des articles de Wikipédia sont bénévoles. Ils coordonnent leurs efforts au sein d'une communauté collaborative, sans dirigeant.\n",
      "Chacun peut publier immédiatement du contenu en ligne, à condition de respecter les règles essentielles établies par la Fondation Wikimedia et par la communauté ; par exemple, la vérifiabilité du contenu, l'admissibilité des articles et garder une attitude cordiale.\n",
      "De nombreuses pages d’aide sont à votre disposition, notamment pour créer un article, modifier un article ou insérer une image. N’hésitez pas à poser une question pour être aidé dans vos premiers pas, notamment dans un des  projets thématiques ou dans divers espaces de discussion.\n",
      "Les pages de discussion servent à centraliser les réflexions et les remarques permettant d’améliorer les articles.\n",
      "Images de qualité sur Wikimédia Commons\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la page à parser\n",
    "url = \"https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal\"\n",
    "\n",
    "# Récupération du contenu HTML de la page\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")  # Utilisation de lxml pour un parsing rapide\n",
    "\n",
    "    # Extraction de tous les titres d'articles (exemple avec <h2>)\n",
    "    titles = soup.find_all(\"p\")\n",
    "    for title in titles:\n",
    "        titre = title.text.strip()\n",
    "        print(title.text.strip())  # Affichage du texte des titres\n",
    "        \n",
    "        \n",
    "else:\n",
    "    print(f\"Erreur lors de l'accès à la page (code {response.status_code})\")\n",
    "    \n",
    "print(titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f55b38-3a82-4282-8ae7-5dddeef86d81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nltk.stem.porter (from versions: none)\n",
      "ERROR: No matching distribution found for nltk.stem.porter\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PorterStemmer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install nltk.stem.porter import PorterStemmer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m porter \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m titre:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(porter\u001b[38;5;241m.\u001b[39mstem(word), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PorterStemmer' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "for words in titre:\n",
    "    print(porter.stem(word), end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04980f07-84ca-4729-886d-8ae3fe36a28d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\squin\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\squin\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\squin\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48fdd0fe-e3e9-4ede-9bec-f50accc030a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"running\"))  # Exemple de stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c941b44-69ff-4e1a-9dab-23cf24b0f2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-grams :\n",
      "de: 26\n",
      "et: 16\n",
      "le: 12\n",
      "à: 12\n",
      "la: 11\n",
      "un: 9\n",
      "dans: 9\n",
      "par: 9\n",
      "château: 7\n",
      "du: 6\n",
      "\n",
      "2-grams :\n",
      "château de: 4\n",
      "de Montsoreau: 4\n",
      "de la: 4\n",
      "le château: 3\n",
      "Le château: 2\n",
      "est un: 2\n",
      "dans le: 2\n",
      "Val de: 2\n",
      "de Loire: 2\n",
      "la Loire: 2\n",
      "\n",
      "3-grams :\n",
      "château de Montsoreau: 3\n",
      "Le château de: 2\n",
      "Val de Loire: 2\n",
      "de la Loire: 2\n",
      "L'encyclopédie libre que: 1\n",
      "libre que vous: 1\n",
      "que vous pouvez: 1\n",
      "vous pouvez améliorer: 1\n",
      "pouvez améliorer Le: 1\n",
      "améliorer Le château: 1\n",
      "\n",
      "4-grams :\n",
      "Le château de Montsoreau: 2\n",
      "L'encyclopédie libre que vous: 1\n",
      "libre que vous pouvez: 1\n",
      "que vous pouvez améliorer: 1\n",
      "vous pouvez améliorer Le: 1\n",
      "pouvez améliorer Le château: 1\n",
      "améliorer Le château de: 1\n",
      "château de Montsoreau est: 1\n",
      "de Montsoreau est un: 1\n",
      "Montsoreau est un château: 1\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "sentence = texte_complet\n",
    "for n in range(1, 5):  # De 1-gram à 4-gram\n",
    "    print(f\"\\n{n}-grams :\")\n",
    "    n_grams = list(ngrams(texte_complet.split(), n))  # Création des n-grams sous forme de liste\n",
    "    n_gram_counts = Counter(n_grams)  # Compter les occurrences\n",
    "    ngram_test = {}\n",
    "    \n",
    "    top_10_ngrams = n_gram_counts.most_common(10)\n",
    "    for ngram, count in top_10_ngrams:\n",
    "        print(f\"{' '.join(ngram)}: {count}\")\n",
    "\n",
    "    # Affichage des n-grams et de leurs occurrences\n",
    "    #for ngram, count in n_gram_counts.items():\n",
    "\n",
    "      #  print(f\"{ngram}: {count}\")\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc39cc41-ea45-4a75-bb58-33412d038698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'encyclopédie libre que vous pouvez améliorer\n",
      "\n",
      "Le château de Montsoreau est un château français de style gothique et Renaissance situé dans le Val de Loire sur la commune de Montsoreau dans le sud-est du département de Maine-et-Loire en région Pays de la Loire.\n",
      "\n",
      "Il abrite depuis le 8 avril 2016 le château de Montsoreau - musée d'Art contemporain. Bâti à un emplacement stratégique, sur un promontoire rocheux à la confluence de la Loire et de la Vienne, il se trouve à l'intersection de trois régions : l'Anjou, le Poitou et la Touraine. Édifice de transition entre le château fort  et le palais urbain, il a pour particularité d'être le seul château de la Loire construit à même le lit du fleuve.\n",
      "\n",
      "Le château de Montsoreau a été immortalisé à de nombreuses reprises, notamment par Alexandre Dumas dans son roman La Dame de Monsoreau écrit entre 1845 et 1846, par J. M. W. Turner dans une aquarelle représentant le château et le bec de Vienne, par François Rabelais dans Gargantua, qui donne Montsoreau en récompense à Ithybole après sa victoire, et par Auguste Rodin, qui l'idéalise dans un dessin conservé au musée Rodin.\n",
      "\n",
      "Classé monument historique en 1862, il est inscrit au patrimoine mondial de l'humanité par l'UNESCO au titre de l'inscription de l'ensemble du Val de Loire entre Sully-sur-Loire et Chalonnes-sur-Loire.\n",
      "\n",
      "Wikipédia est un projet d’encyclopédie collective en ligne, universelle, multilingue et fonctionnant sur le principe du wiki. Ce projet vise à offrir un contenu librement réutilisable, objectif et vérifiable, que chacun peut modifier et améliorer.\n",
      "\n",
      "Wikipédia est définie par des principes fondateurs. Son contenu est sous licence Creative Commons BY-SA. Il peut être copié et réutilisé sous la même licence, sous réserve d'en respecter les conditions. Wikipédia fournit tous ses contenus gratuitement, sans publicité, et sans recourir à l'exploitation des données personnelles de ses utilisateurs.\n",
      "\n",
      "Les rédacteurs des articles de Wikipédia sont bénévoles. Ils coordonnent leurs efforts au sein d'une communauté collaborative, sans dirigeant.\n",
      "\n",
      "Chacun peut publier immédiatement du contenu en ligne, à condition de respecter les règles essentielles établies par la Fondation Wikimedia et par la communauté ; par exemple, la vérifiabilité du contenu, l'admissibilité des articles et garder une attitude cordiale.\n",
      "\n",
      "De nombreuses pages d’aide sont à votre disposition, notamment pour créer un article, modifier un article ou insérer une image. N’hésitez pas à poser une question pour être aidé dans vos premiers pas, notamment dans un des  projets thématiques ou dans divers espaces de discussion.\n",
      "\n",
      "Les pages de discussion servent à centraliser les réflexions et les remarques permettant d’améliorer les articles.\n",
      "\n",
      "Images de qualité sur Wikimédia Commons\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la page à parser\n",
    "url = \"https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal\"\n",
    "\n",
    "# Récupération du contenu HTML de la page\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")  # Utilisation de lxml pour un parsing rapide\n",
    "\n",
    "    # Extraction de tous les paragraphes (<p>)\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "\n",
    "    # Stocker les paragraphes dans une seule variable texte\n",
    "    texte_complet = \"\\n\\n\".join(p.text.strip() for p in paragraphs if p.text.strip())\n",
    "\n",
    "    # Affichage du texte complet\n",
    "    print(texte_complet)\n",
    "\n",
    "    # (Optionnel) Enregistrement dans un fichier texte\n",
    "    with open(\"wikipedia_paragraphs.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(texte_complet)\n",
    "\n",
    "else:\n",
    "    print(f\"Erreur lors de l'accès à la page (code {response.status_code})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456ce3fa-8424-40db-8f69-e365d6631e84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2570653632.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[44], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    from nltk\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentence =\"He goes to school daily\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "primt(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bc28f0e-fdca-4e7d-acff-8f69eea533b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ac18ff9-c74f-4722-8b9f-a891d1692a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/ca/45/7b43e89b30fe73e32fd8b8ab80c407d326761530a88abd823ec8623772a6/spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/de/30/ceb9217cdba72bc0bf8466e373e12e5a42945cc85eda0a7c479e319e07ae/murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/56/c8/75f75889401b20f4c3a7c5965dda09df42913e904ddc2ffe7ef3bdf25061/cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.4.0,>=8.3.4 from https://files.pythonhosted.org/packages/d9/98/f910b8d8113ab9b955a68e9bbf0d5bd0e828f22dd6d3c226af6ec3970817/thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/bb/da/657a685f63028dcb00ccdc4ac125ed347c8bff6fa0dab6a9eb3dc45f3223/srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.5.0,>=0.1.0 from https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Obtaining dependency information for typer<1.0.0,>=0.3.0 from https://files.pythonhosted.org/packages/d0/cc/0a838ba5ca64dc832aa43f727bd586309846b0ffb2ce52422543e6075e8a/typer-0.15.1-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/c3/6b/068c2ea7a712bf805c62445bd9e9c06d7340358ef2824150eceac027444b/langcodes-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/5d/e9/5a5ffd9b286db82be70d677d0a91e4d58f7912bb8dd026ddeeb4abe70679/language_data-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for blis<1.3.0,>=1.2.0 from https://files.pythonhosted.org/packages/c4/d9/b647ef53c33c82c1fa2ed217c5793de551a38fb1e5b2430f59c3ecba4c86/blis-1.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-1.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\squin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<1.0.0,>=0.7.0 from https://files.pythonhosted.org/packages/1f/6e/b64600156934dab14cc8b403095a9ea8bd722aad2e775673c68346b76220/cloudpathlib-0.20.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for marisa-trie>=1.1.0 from https://files.pythonhosted.org/packages/fc/98/574b4e143e0a2f5f71af8716b6c4a8a46220f75a6e0847ce7d11ee0ba4aa/marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\squin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.2 MB 4.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/12.2 MB 9.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/12.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/12.2 MB 12.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.0/12.2 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.5/12.2 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.2/12.2 MB 13.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.2/12.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.4/12.2 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.4/12.2 MB 16.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.5/12.2 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.2 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.9/12.2 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.8/12.2 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/183.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 183.0/183.0 kB ? eta 0:00:00\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.6/632.6 kB 38.9 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.2/1.5 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 31.5 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.3/50.3 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading blis-1.2.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.3/6.2 MB 40.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.2/6.2 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.1/6.2 MB 32.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.1/6.2 MB 29.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.1/6.2 MB 27.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 24.9 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.4 MB 32.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.6/5.4 MB 33.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.3/5.4 MB 34.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 31.3 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 242.4/242.4 kB ? eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 152.0/152.0 kB ? eta 0:00:00\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, rich, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 rich-13.9.4 shellingham-1.5.4 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "579222a5-1c72-4506-8e76-f60281f0b3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m[x] No compatible package found for 'fr_core_web_sm' (spaCy v3.8.4)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_web_sm\n",
    "\n",
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0073070a-7323-4c66-b84c-d1170ac7ae09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He PRON nsubj\n",
      "goes VERB ROOT\n",
      "to ADP prep\n",
      "school NOUN pobj\n",
      "daily ADV advmod\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"He goes to school daily\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e54ea-cfe4-4b94-8d79-850c75178a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cad1016-b13f-4aa9-8dc0-2dd55e402b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenue dans le jeu 'Devine le nombre' !\n",
      "J'ai choisi un nombre entre 1 et 100. À toi de le deviner !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop bas ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trop haut ! Essaie encore.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entre un nombre :  93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bravo ! Tu as trouvé le nombre 93 en 7 essais. 🎉\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def jeu_devine_nombre():\n",
    "    print(\"Bienvenue dans le jeu 'Devine le nombre' !\")\n",
    "    print(\"J'ai choisi un nombre entre 1 et 100. À toi de le deviner !\")\n",
    "\n",
    "    nombre_secret = random.randint(1, 100)\n",
    "    tentative = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choix = int(input(\"Entre un nombre : \"))\n",
    "            tentative += 1\n",
    "            \n",
    "            if choix < nombre_secret:\n",
    "                print(\"Trop bas ! Essaie encore.\")\n",
    "            elif choix > nombre_secret:\n",
    "                print(\"Trop haut ! Essaie encore.\")\n",
    "            else:\n",
    "                print(f\"Bravo ! Tu as trouvé le nombre {nombre_secret} en {tentative} essais. 🎉\")\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"Oups ! Entre un nombre valide.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jeu_devine_nombre()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f2da81-8c4f-469f-81fd-8f198ed07e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \n\u001b[0;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mlaod(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m text_to_analyze \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\cli\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Needed for testing\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download \u001b[38;5;28;01mas\u001b[39;00m download_module  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app, setup_cli  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\cli\\download.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urljoin\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyper\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m about\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\typer\\__init__.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_file \u001b[38;5;28;01mas\u001b[39;00m open_file\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors \u001b[38;5;28;01mas\u001b[39;00m colors\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Typer \u001b[38;5;28;01mas\u001b[39;00m Typer\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m launch \u001b[38;5;28;01mas\u001b[39;00m launch\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run \u001b[38;5;28;01mas\u001b[39;00m run\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\typer\\main.py:57\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Traceback\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rich_utils\n\u001b[1;32m---> 57\u001b[0m     console_stderr \u001b[38;5;241m=\u001b[39m rich_utils\u001b[38;5;241m.\u001b[39m_get_rich_console(stderr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     rich \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\typer\\rich_utils.py:129\u001b[0m, in \u001b[0;36m_get_rich_console\u001b[1;34m(stderr)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_rich_console\u001b[39m(stderr: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Console:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Console(\n\u001b[0;32m    130\u001b[0m         theme\u001b[38;5;241m=\u001b[39mTheme(\n\u001b[0;32m    131\u001b[0m             {\n\u001b[0;32m    132\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_OPTION,\n\u001b[0;32m    133\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswitch\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_SWITCH,\n\u001b[0;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_option\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_NEGATIVE_OPTION,\n\u001b[0;32m    135\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_switch\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_NEGATIVE_SWITCH,\n\u001b[0;32m    136\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetavar\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_METAVAR,\n\u001b[0;32m    137\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetavar_sep\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_METAVAR_SEPARATOR,\n\u001b[0;32m    138\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m: STYLE_USAGE,\n\u001b[0;32m    139\u001b[0m             },\n\u001b[0;32m    140\u001b[0m         ),\n\u001b[0;32m    141\u001b[0m         highlighter\u001b[38;5;241m=\u001b[39mhighlighter,\n\u001b[0;32m    142\u001b[0m         color_system\u001b[38;5;241m=\u001b[39mCOLOR_SYSTEM,\n\u001b[0;32m    143\u001b[0m         force_terminal\u001b[38;5;241m=\u001b[39mFORCE_TERMINAL,\n\u001b[0;32m    144\u001b[0m         width\u001b[38;5;241m=\u001b[39mMAX_WIDTH,\n\u001b[0;32m    145\u001b[0m         stderr\u001b[38;5;241m=\u001b[39mstderr,\n\u001b[0;32m    146\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\console.py:691\u001b[0m, in \u001b[0;36mConsole.__init__\u001b[1;34m(self, color_system, force_terminal, force_jupyter, force_interactive, soft_wrap, theme, stderr, file, quiet, width, height, style, no_color, tab_size, record, markup, emoji, emoji_variant, highlight, log_time, log_path, log_time_format, highlighter, legacy_windows, safe_box, get_datetime, get_time, _environ)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_emoji_variant: Optional[EmojiVariant] \u001b[38;5;241m=\u001b[39m emoji_variant\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_highlight \u001b[38;5;241m=\u001b[39m highlight\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegacy_windows: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 691\u001b[0m     (detect_legacy_windows() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_jupyter)\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m legacy_windows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m legacy_windows\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    697\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_environ\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOLUMNS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\console.py:590\u001b[0m, in \u001b[0;36mdetect_legacy_windows\u001b[1;34m()\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_legacy_windows\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    589\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Detect legacy Windows.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WINDOWS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_windows_console_features()\u001b[38;5;241m.\u001b[39mvt\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\console.py:584\u001b[0m, in \u001b[0;36mget_windows_console_features\u001b[1;34m()\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _windows_console_features\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_windows\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_windows_console_features\n\u001b[1;32m--> 584\u001b[0m _windows_console_features \u001b[38;5;241m=\u001b[39m get_windows_console_features()\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _windows_console_features\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\_windows.py:48\u001b[0m, in \u001b[0;36mget_windows_console_features\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m handle \u001b[38;5;241m=\u001b[39m GetStdHandle()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     console_mode \u001b[38;5;241m=\u001b[39m GetConsoleMode(handle)\n\u001b[0;32m     49\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LegacyWindowsError:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\rich\\_win32_console.py:111\u001b[0m, in \u001b[0;36mGetConsoleMode\u001b[1;34m(std_handle)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the current input mode of a console's input buffer\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03mor the current output mode of a console screen buffer.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m        https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m console_mode \u001b[38;5;241m=\u001b[39m wintypes\u001b[38;5;241m.\u001b[39mDWORD()\n\u001b[1;32m--> 111\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(_GetConsoleMode(std_handle, console_mode))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LegacyWindowsError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get legacy Windows Console Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.laod(\"en_core_web_sm\")\n",
    "\n",
    "text_to_analyze = \"cat\"\n",
    "doc = nlp(text_to_analyze)\n",
    "\n",
    "vector_list = [token.vector for token in doc]\n",
    "print(\"Vecteurs de '{}' : {}\".format(text_to_analyze, vector_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855734e-92f3-4054-9155-4588b824347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vecteur du mot 'this':\", cbow_model.vw[\"this\"])\n",
    "\n",
    "print(\"Similarite entre 'this' et 'class':\", cbow_model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de869ce-0a0b-499e-b52a-beedeeec1a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'fr_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Charger le modèle spaCy\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Texte à analyser\u001b[39;00m\n\u001b[0;32m      5\u001b[0m text_to_analyze \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParis is the capital of France.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn 2015, its population was# Analyser le texte\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'fr_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"fr_core_web_sm\")\n",
    "# Texte à analyser\n",
    "text_to_analyze = \"Paris is the capital of France.\" + \"In 2015, its population was# Analyser le texte\"\n",
    "doc = nlp(texte_complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76757369-e06c-4525-871e-3ced86d4414a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entité: un, Début: 77, Fin: 79, Catégorie: ORG\n",
      "Entité: Renaissance, Début: 118, Fin: 129, Catégorie: ORG\n",
      "Entité: Val de Loire, Début: 144, Fin: 156, Catégorie: ORG\n",
      "Entité: dans, Début: 186, Fin: 190, Catégorie: NORP\n",
      "Entité: Maine, Début: 220, Fin: 225, Catégorie: GPE\n",
      "Entité: Il abrite depuis le, Début: 264, Fin: 283, Catégorie: PERSON\n",
      "Entité: 8 avril 2016, Début: 284, Fin: 296, Catégorie: TIME\n",
      "Entité: château de Montsoreau - musée, Début: 300, Fin: 329, Catégorie: ORG\n",
      "Entité: un, Début: 357, Fin: 359, Catégorie: ORG\n",
      "Entité: sur un promontoire rocheux à la confluence de la Loire et de la Vienne, Début: 385, Fin: 455, Catégorie: ORG\n",
      "Entité: il se trouve, Début: 457, Fin: 469, Catégorie: PERSON\n",
      "Entité: Poitou, Début: 518, Fin: 524, Catégorie: GPE\n",
      "Entité: Touraine, Début: 531, Fin: 539, Catégorie: ORG\n",
      "Entité: château fort  et, Début: 572, Fin: 588, Catégorie: FAC\n",
      "Entité: château de la Loire, Début: 646, Fin: 665, Catégorie: ORG\n",
      "Entité: même le, Début: 678, Fin: 685, Catégorie: PERSON\n",
      "Entité: Le château de Montsoreau, Début: 702, Fin: 726, Catégorie: ORG\n",
      "Entité: Alexandre Dumas, Début: 785, Fin: 800, Catégorie: PERSON\n",
      "Entité: dans, Début: 801, Fin: 805, Catégorie: NORP\n",
      "Entité: La Dame de Monsoreau, Début: 816, Fin: 836, Catégorie: ORG\n",
      "Entité: 1845, Début: 849, Fin: 853, Catégorie: DATE\n",
      "Entité: 1846, Début: 857, Fin: 861, Catégorie: DATE\n",
      "Entité: J. M. W. Turner, Début: 867, Fin: 882, Catégorie: PERSON\n",
      "Entité: dans, Début: 883, Fin: 887, Catégorie: NORP\n",
      "Entité: une, Début: 888, Fin: 891, Catégorie: ORG\n",
      "Entité: château et le bec de Vienne, Début: 918, Fin: 945, Catégorie: ORG\n",
      "Entité: François Rabelais, Début: 951, Fin: 968, Catégorie: ORG\n",
      "Entité: Gargantua, Début: 974, Fin: 983, Catégorie: PERSON\n",
      "Entité: Ithybole, Début: 1022, Fin: 1030, Catégorie: ORG\n",
      "Entité: Auguste Rodin, Début: 1057, Fin: 1070, Catégorie: PERSON\n",
      "Entité: qui l'idéalise, Début: 1072, Fin: 1086, Catégorie: ORG\n",
      "Entité: un, Début: 1092, Fin: 1094, Catégorie: ORG\n",
      "Entité: Classé, Début: 1128, Fin: 1134, Catégorie: ORG\n",
      "Entité: 1862, Début: 1158, Fin: 1162, Catégorie: DATE\n",
      "Entité: titre de l'inscription de l'ensemble, Début: 1231, Fin: 1267, Catégorie: PERSON\n",
      "Entité: Val de Loire, Début: 1271, Fin: 1283, Catégorie: ORG\n",
      "Entité: Wikipédia, Début: 1331, Fin: 1340, Catégorie: GPE\n",
      "Entité: un, Début: 1345, Fin: 1347, Catégorie: ORG\n",
      "Entité: d’encyclopédie, Début: 1355, Fin: 1369, Catégorie: PERSON\n",
      "Entité: universelle, Début: 1391, Fin: 1402, Catégorie: ORG\n",
      "Entité: multilingue, Début: 1404, Fin: 1415, Catégorie: PERSON\n",
      "Entité: un, Début: 1481, Fin: 1483, Catégorie: ORG\n",
      "Entité: Wikipédia, Début: 1580, Fin: 1589, Catégorie: GPE\n",
      "Entité: définie, Début: 1594, Fin: 1601, Catégorie: PERSON\n",
      "Entité: Creative Commons BY-SA, Début: 1661, Fin: 1683, Catégorie: ORG\n",
      "Entité: Il peut être copié, Début: 1685, Fin: 1703, Catégorie: PERSON\n",
      "Entité: la même licence, Début: 1722, Fin: 1737, Catégorie: FAC\n",
      "Entité: Wikipédia, Début: 1783, Fin: 1792, Catégorie: GPE\n",
      "Entité: Wikipédia, Début: 1961, Fin: 1970, Catégorie: GPE\n",
      "Entité: Chacun, Début: 2074, Fin: 2080, Catégorie: ORG\n",
      "Entité: par exemple, Début: 2237, Fin: 2248, Catégorie: PERSON\n",
      "Entité: un, Début: 2416, Fin: 2418, Catégorie: ORG\n",
      "Entité: un, Début: 2437, Fin: 2439, Catégorie: ORG\n",
      "Entité: être aidé dans, Début: 2510, Fin: 2524, Catégorie: PERSON\n",
      "Entité: dans, Début: 2553, Fin: 2557, Catégorie: NORP\n",
      "Entité: un, Début: 2558, Fin: 2560, Catégorie: ORG\n",
      "Entité: dans, Début: 2589, Fin: 2593, Catégorie: NORP\n",
      "Entité: Wikimédia Commons, Début: 2763, Fin: 2780, Catégorie: ORG\n"
     ]
    }
   ],
   "source": [
    "# Afficher les informations sur les entités\n",
    "for entity in doc.ents:\n",
    "    entity_text = entity.text\n",
    "    start_char = entity.start_char\n",
    "    end_char = entity.end_char\n",
    "    label = entity.label_\n",
    "    print(\"Entité: {}, Début: {}, Fin: {}, Catégorie: {}\".format(entity_text,\n",
    "    start_char, end_char, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b90465f0-af41-4b8d-a5ad-01afa9256819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading vader_location: Package 'vader_location' not\n",
      "[nltk_data]     found in index\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\squin/nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvader_location\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[1;32m----> 5\u001b[0m sia \u001b[38;5;241m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[0;32m      6\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m sia\u001b[38;5;241m.\u001b[39mpolarity_scores(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis movie is good\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentiment)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\sentiment\\vader.py:340\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.__init__\u001b[1;34m(self, lexicon_file)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    338\u001b[0m     lexicon_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    339\u001b[0m ):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon_file \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mload(lexicon_file)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_lex_dict()\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstants \u001b[38;5;241m=\u001b[39m VaderConstants()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\squin/nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\squin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_location')\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment = sia.polarity_scores(\"this movie is good\")\n",
    "print(sentiment)\n",
    "sentiment = sia.polarity_scores(\"this movie is not very good\")\n",
    "print(sentiment)\n",
    "sentiment = sia.polarity_scores(\"this movie is bad\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcd26c-de59-415f-b224-70a40bd0fc88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
